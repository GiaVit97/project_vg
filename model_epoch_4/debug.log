2022-01-31 19:14:31   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-31 19:14:31   The outputs are being saved in drive/MyDrive/aml_training
2022-01-31 19:14:31   Using 1 GPUs and 2 CPUs
2022-01-31 19:14:31   Loading dataset Pitts30k from folder /content/
2022-01-31 19:14:31   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-31 19:14:31   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-31 19:14:32   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-31 19:14:32   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-31 19:14:32   Using NetVlad network
2022-01-31 19:14:34   using Adam optimizer
2022-01-31 19:14:34   Output dimension of the model is 16384
2022-01-31 19:14:34   Patience: 3
2022-01-31 19:14:34   not improved num: 0
2022-01-31 19:14:34   Start training epoch: 00
2022-01-31 19:14:34   Cache: 0 / 5
2022-01-31 19:18:45   
Traceback (most recent call last):
  File "project_vg/train.py", line 139, in <module>
    triplets_ds.compute_triplets(args, model)
  File "/content/project_vg/datasets_ws.py", line 254, in compute_triplets
    cache = self.compute_cache(args, model, subset_ds, (len(self), args.features_dim))
  File "/content/project_vg/datasets_ws.py", line 215, in compute_cache
    cache[indexes.numpy()] = features.cpu().numpy()
KeyboardInterrupt

2022-01-31 19:21:32   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-31 19:21:32   The outputs are being saved in drive/MyDrive/aml_training
2022-01-31 19:21:32   Using 1 GPUs and 2 CPUs
2022-01-31 19:21:32   Loading dataset Pitts30k from folder /content/
2022-01-31 19:21:32   Images resized to 800x600
2022-01-31 19:21:33   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-31 19:21:33   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-31 19:21:33   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-31 19:21:33   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-31 19:21:33   Using NetVlad network
2022-01-31 19:21:35   using Adam optimizer
2022-01-31 19:21:35   Output dimension of the model is 16384
2022-01-31 19:21:35   Patience: 3
2022-01-31 19:21:35   not improved num: 0
2022-01-31 19:21:35   Start training epoch: 00
2022-01-31 19:21:35   Cache: 0 / 5
2022-01-31 19:41:36   Epoch[00](0/5): current batch triplet loss = 0.0376, average epoch triplet loss = 0.0425
2022-01-31 19:41:36   Cache: 1 / 5
2022-02-01 11:39:03   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', test_only=False, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-02-01 11:39:04   The outputs are being saved in drive/MyDrive/aml_training
2022-02-01 11:39:04   Using 1 GPUs and 2 CPUs
2022-02-01 11:39:04   Loading dataset Pitts30k from folder /content/
2022-02-01 11:39:04   Images resized to 800x600
2022-02-01 11:39:04   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-02-01 11:39:04   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-02-01 11:39:04   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-02-01 11:39:05   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-02-01 11:39:05   Using NetVlad network
2022-02-01 11:39:08   using Adam optimizer
2022-02-01 11:39:08   Output dimension of the model is 16384
2022-02-01 11:39:08   Patience: 3
2022-02-01 11:39:08   not improved num: 0
2022-02-01 11:39:08   Start training epoch: 00
2022-02-01 11:39:08   Cache: 0 / 5
2022-02-01 11:49:44   Epoch[00](0/5): current batch triplet loss = 0.0338, average epoch triplet loss = 0.0416
2022-02-01 11:49:44   Cache: 1 / 5
2022-02-01 12:00:37   Epoch[00](1/5): current batch triplet loss = 0.0467, average epoch triplet loss = 0.0384
2022-02-01 12:00:37   Cache: 2 / 5
2022-02-01 12:11:33   Epoch[00](2/5): current batch triplet loss = 0.0122, average epoch triplet loss = 0.0357
2022-02-01 12:11:33   Cache: 3 / 5
2022-02-01 12:22:28   Epoch[00](3/5): current batch triplet loss = 0.0512, average epoch triplet loss = 0.0340
2022-02-01 12:22:28   Cache: 4 / 5
2022-02-01 12:33:24   Epoch[00](4/5): current batch triplet loss = 0.0464, average epoch triplet loss = 0.0330
2022-02-01 12:33:24   Finished epoch 00 in 0:54:15, average epoch triplet loss = 0.0330
2022-02-01 12:33:24   Extracting database features for evaluation/testing
2022-02-01 12:37:11   Extracting queries features for evaluation/testing
2022-02-01 12:40:06   Calculating recalls
2022-02-01 12:40:39   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 84.6, R@5: 94.0, R@10: 96.4, R@20: 97.7
2022-02-01 12:40:39   Improved: previous best R@5 = 0.0, current R@5 = 94.0
2022-02-01 12:40:39   Start training epoch: 01
2022-02-01 12:40:39   Cache: 0 / 5
2022-02-01 12:52:54   Epoch[01](0/5): current batch triplet loss = 0.0477, average epoch triplet loss = 0.0266
2022-02-01 12:52:54   Cache: 1 / 5
2022-02-01 13:03:51   Epoch[01](1/5): current batch triplet loss = 0.0235, average epoch triplet loss = 0.0264
2022-02-01 13:03:51   Cache: 2 / 5
2022-02-01 13:14:50   Epoch[01](2/5): current batch triplet loss = 0.0432, average epoch triplet loss = 0.0256
2022-02-01 13:14:50   Cache: 3 / 5
2022-02-02 15:19:42   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', test_only=False, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-02-02 15:19:43   The outputs are being saved in drive/MyDrive/aml_training
2022-02-02 15:19:43   Using 1 GPUs and 2 CPUs
2022-02-02 15:19:43   Loading dataset Pitts30k from folder /content/
2022-02-02 15:19:43   Images resized to 800x600
2022-02-02 15:19:44   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-02-02 15:19:44   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-02-02 15:19:44   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-02-02 15:19:44   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-02-02 15:19:44   Using NetVlad network
2022-02-02 15:19:46   using Adam optimizer
2022-02-02 15:19:46   Output dimension of the model is 16384
2022-02-02 15:19:50   Patience: 3
2022-02-02 15:19:50   not improved num: 0
2022-02-02 15:19:50   Start training epoch: 01
2022-02-02 15:19:50   Cache: 0 / 5
2022-02-02 15:39:36   Epoch[01](0/5): current batch triplet loss = 0.0214, average epoch triplet loss = 0.0236
2022-02-02 15:39:36   Cache: 1 / 5
2022-02-04 17:12:55   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', test_only=False, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-02-04 17:12:56   The outputs are being saved in drive/MyDrive/aml_training
2022-02-04 17:12:56   Using 1 GPUs and 2 CPUs
2022-02-04 17:12:56   Loading dataset Pitts30k from folder /content/
2022-02-04 17:12:56   Images resized to 800x600
2022-02-04 17:12:56   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-02-04 17:12:56   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-02-04 17:12:57   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-02-04 17:12:57   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-02-04 17:12:57   Using NetVlad network
2022-02-04 17:12:59   using Adam optimizer
2022-02-04 17:12:59   Output dimension of the model is 16384
2022-02-04 17:13:03   Patience: 3
2022-02-04 17:13:03   not improved num: 0
2022-02-04 17:13:03   Start training epoch: 01
2022-02-04 17:13:03   Cache: 0 / 5
2022-02-04 17:31:46   Epoch[01](0/5): current batch triplet loss = 0.0214, average epoch triplet loss = 0.0236
2022-02-04 17:31:46   Cache: 1 / 5
2022-02-04 17:39:15   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', test_only=False, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-02-04 17:39:15   The outputs are being saved in drive/MyDrive/aml_training
2022-02-04 17:39:15   Using 1 GPUs and 2 CPUs
2022-02-04 17:39:15   Loading dataset Pitts30k from folder /content/
2022-02-04 17:39:16   Images resized to 800x600
2022-02-04 17:39:16   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-02-04 17:39:16   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-02-04 17:39:16   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-02-04 17:39:17   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-02-04 17:39:17   Using NetVlad network
2022-02-04 17:39:21   using Adam optimizer
2022-02-04 17:39:21   Output dimension of the model is 16384
2022-02-04 17:39:22   Patience: 3
2022-02-04 17:39:22   not improved num: 0
2022-02-04 17:39:22   Start training epoch: 01
2022-02-04 17:39:22   Cache: 0 / 5
2022-02-04 17:58:00   Epoch[01](0/5): current batch triplet loss = 0.0214, average epoch triplet loss = 0.0236
2022-02-04 17:58:00   Cache: 1 / 5
2022-02-04 18:16:41   Epoch[01](1/5): current batch triplet loss = 0.0278, average epoch triplet loss = 0.0225
2022-02-04 18:16:41   Cache: 2 / 5
2022-02-04 18:35:21   Epoch[01](2/5): current batch triplet loss = 0.0080, average epoch triplet loss = 0.0215
2022-02-04 18:35:21   Cache: 3 / 5
2022-02-04 18:54:00   Epoch[01](3/5): current batch triplet loss = 0.0353, average epoch triplet loss = 0.0211
2022-02-04 18:54:00   Cache: 4 / 5
2022-02-04 19:12:45   Epoch[01](4/5): current batch triplet loss = 0.0323, average epoch triplet loss = 0.0209
2022-02-04 19:12:45   Finished epoch 01 in 1:33:22, average epoch triplet loss = 0.0209
2022-02-04 19:12:45   Extracting database features for evaluation/testing
2022-02-04 19:18:58   Extracting queries features for evaluation/testing
2022-02-04 19:23:28   Calculating recalls
2022-02-04 19:24:11   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 86.3, R@5: 94.8, R@10: 96.8, R@20: 98.0
2022-02-04 19:24:11   Improved: previous best R@5 = 94.0, current R@5 = 94.8
2022-02-04 19:24:13   Start training epoch: 02
2022-02-04 19:24:13   Cache: 0 / 5
2022-02-04 19:44:56   Epoch[02](0/5): current batch triplet loss = 0.0373, average epoch triplet loss = 0.0213
2022-02-04 19:44:56   Cache: 1 / 5
2022-02-06 08:43:36   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', test_only=False, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-02-06 08:43:37   The outputs are being saved in drive/MyDrive/aml_training
2022-02-06 08:43:37   Using 1 GPUs and 2 CPUs
2022-02-06 08:43:37   Loading dataset Pitts30k from folder /content/
2022-02-06 08:43:37   Images resized to 800x600
2022-02-06 08:43:37   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-02-06 08:43:37   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-02-06 08:43:38   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-02-06 08:43:38   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-02-06 08:43:38   Using NetVlad network
2022-02-06 08:43:40   using Adam optimizer
2022-02-06 08:43:40   Output dimension of the model is 16384
2022-02-06 08:43:44   Patience: 3
2022-02-06 08:43:44   not improved num: 0
2022-02-06 08:43:44   Start training epoch: 02
2022-02-06 08:43:44   Cache: 0 / 5
2022-02-06 09:07:40   Epoch[02](0/5): current batch triplet loss = 0.0151, average epoch triplet loss = 0.0162
2022-02-06 09:07:40   Cache: 1 / 5
2022-02-06 09:31:34   Epoch[02](1/5): current batch triplet loss = 0.0208, average epoch triplet loss = 0.0158
2022-02-06 09:31:34   Cache: 2 / 5
2022-02-06 09:55:28   Epoch[02](2/5): current batch triplet loss = 0.0038, average epoch triplet loss = 0.0153
2022-02-06 09:55:28   Cache: 3 / 5
2022-02-06 10:19:24   Epoch[02](3/5): current batch triplet loss = 0.0274, average epoch triplet loss = 0.0151
2022-02-06 10:19:24   Cache: 4 / 5
2022-02-06 10:43:25   Epoch[02](4/5): current batch triplet loss = 0.0208, average epoch triplet loss = 0.0151
2022-02-06 10:43:25   Finished epoch 02 in 1:59:41, average epoch triplet loss = 0.0151
2022-02-06 10:43:25   Extracting database features for evaluation/testing
2022-02-06 10:50:22   Extracting queries features for evaluation/testing
2022-02-06 10:55:40   Calculating recalls
2022-02-06 10:56:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 86.6, R@5: 94.9, R@10: 96.9, R@20: 98.2
2022-02-06 10:56:19   Improved: previous best R@5 = 94.8, current R@5 = 94.9
2022-02-06 10:56:21   Start training epoch: 03
2022-02-06 10:56:21   Cache: 0 / 5
2022-02-06 11:20:24   Epoch[03](0/5): current batch triplet loss = 0.0327, average epoch triplet loss = 0.0184
2022-02-06 11:20:24   Cache: 1 / 5
2022-02-06 11:44:26   Epoch[03](1/5): current batch triplet loss = 0.0176, average epoch triplet loss = 0.0184
2022-02-06 11:44:26   Cache: 2 / 5
2022-02-06 12:08:38   Epoch[03](2/5): current batch triplet loss = 0.0172, average epoch triplet loss = 0.0179
2022-02-06 12:08:38   Cache: 3 / 5
2022-02-06 12:32:48   Epoch[03](3/5): current batch triplet loss = 0.0224, average epoch triplet loss = 0.0181
2022-02-06 12:32:48   Cache: 4 / 5
2022-02-06 12:56:54   Epoch[03](4/5): current batch triplet loss = 0.0302, average epoch triplet loss = 0.0181
2022-02-06 12:56:54   Finished epoch 03 in 2:00:33, average epoch triplet loss = 0.0181
2022-02-06 12:56:54   Extracting database features for evaluation/testing
2022-02-06 13:03:52   Extracting queries features for evaluation/testing
2022-02-06 13:09:14   Calculating recalls
2022-02-06 13:09:55   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 87.6, R@5: 95.5, R@10: 97.3, R@20: 98.3
2022-02-06 13:09:55   Improved: previous best R@5 = 94.9, current R@5 = 95.5
2022-02-06 13:09:56   Start training epoch: 04
2022-02-06 13:09:56   Cache: 0 / 5
2022-02-06 13:34:04   Epoch[04](0/5): current batch triplet loss = 0.0099, average epoch triplet loss = 0.0171
2022-02-06 13:34:04   Cache: 1 / 5
2022-02-06 13:58:02   Epoch[04](1/5): current batch triplet loss = 0.0102, average epoch triplet loss = 0.0172
2022-02-06 13:58:02   Cache: 2 / 5
2022-02-06 14:22:02   Epoch[04](2/5): current batch triplet loss = 0.0042, average epoch triplet loss = 0.0172
2022-02-06 14:22:02   Cache: 3 / 5
2022-02-06 14:46:11   Epoch[04](3/5): current batch triplet loss = 0.0057, average epoch triplet loss = 0.0168
2022-02-06 14:46:11   Cache: 4 / 5
2022-02-08 19:12:01   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='aml_training', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', img_height=600, img_width=800, infer_batch_size=16, lr=1e-05, margin=0.1, model_folder=None, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/aml_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, test_datasets='pitts30k', test_only=False, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-02-08 19:12:02   The outputs are being saved in drive/MyDrive/aml_training
2022-02-08 19:12:02   Using 1 GPUs and 2 CPUs
2022-02-08 19:12:02   Loading dataset Pitts30k from folder /content/
2022-02-08 19:12:02   Images resized to 800x600
2022-02-08 19:12:02   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-02-08 19:12:02   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-02-08 19:12:03   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-02-08 19:12:03   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-02-08 19:12:03   Using NetVlad network
2022-02-08 19:12:05   using Adam optimizer
2022-02-08 19:12:05   Output dimension of the model is 16384
2022-02-08 19:12:09   Patience: 3
2022-02-08 19:12:09   not improved num: 0
2022-02-08 19:12:09   Start training epoch: 04
2022-02-08 19:12:09   Cache: 0 / 5
2022-02-08 19:31:41   Epoch[04](0/5): current batch triplet loss = 0.0053, average epoch triplet loss = 0.0105
2022-02-08 19:31:41   Cache: 1 / 5
