2022-01-29 08:20:06   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='Netvlad_B-GS-R', data_aug='B-GS-R', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/Netvlad_B-GS-R', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-29 08:20:06   The outputs are being saved in drive/MyDrive/Netvlad_B-GS-R
2022-01-29 08:20:06   Using 1 GPUs and 2 CPUs
2022-01-29 08:20:06   Loading dataset Pitts30k from folder /content/
2022-01-29 08:20:07   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-29 08:20:07   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-29 08:20:07   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-29 08:20:07   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-29 08:20:07   Using NetVlad network
2022-01-29 08:20:09   using Adam optimizer
2022-01-29 08:20:09   Output dimension of the model is 16384
2022-01-29 08:20:09   Patience: 3
2022-01-29 08:20:09   not improved num: 0
2022-01-29 08:20:09   Start training epoch: 00
2022-01-29 08:20:09   Cache: 0 / 5
2022-01-29 08:32:55   Epoch[00](0/5): current batch triplet loss = 0.0367, average epoch triplet loss = 0.0948
2022-01-29 08:32:55   Cache: 1 / 5
2022-01-29 08:45:43   Epoch[00](1/5): current batch triplet loss = 0.1293, average epoch triplet loss = 0.0896
2022-01-29 08:45:43   Cache: 2 / 5
2022-01-29 08:58:30   Epoch[00](2/5): current batch triplet loss = 0.1033, average epoch triplet loss = 0.0859
2022-01-29 08:58:30   Cache: 3 / 5
2022-01-29 09:11:19   Epoch[00](3/5): current batch triplet loss = 0.0899, average epoch triplet loss = 0.0834
2022-01-29 09:11:19   Cache: 4 / 5
2022-01-29 09:24:08   Epoch[00](4/5): current batch triplet loss = 0.0368, average epoch triplet loss = 0.0806
2022-01-29 09:24:08   Finished epoch 00 in 1:03:59, average epoch triplet loss = 0.0806
2022-01-29 09:24:08   Extracting database features for evaluation/testing
2022-01-29 09:28:26   Extracting queries features for evaluation/testing
2022-01-29 09:31:45   Calculating recalls
2022-01-29 09:32:30   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 80.9, R@5: 92.1, R@10: 95.1, R@20: 97.2
2022-01-29 09:32:30   Improved: previous best R@5 = 0.0, current R@5 = 92.1
2022-01-29 09:32:30   Start training epoch: 01
2022-01-29 09:32:30   Cache: 0 / 5
2022-01-29 09:45:41   Epoch[01](0/5): current batch triplet loss = 0.0711, average epoch triplet loss = 0.0690
2022-01-29 09:45:41   Cache: 1 / 5
2022-01-29 10:44:42   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='Netvlad_B-GS-R', data_aug='B-GS-R', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/Netvlad_B-GS-R', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-29 10:44:44   The outputs are being saved in drive/MyDrive/Netvlad_B-GS-R
2022-01-29 10:44:44   Using 1 GPUs and 2 CPUs
2022-01-29 10:44:44   Loading dataset Pitts30k from folder /content/
2022-01-29 10:44:44   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-29 10:44:44   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-29 10:44:44   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-29 10:44:45   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-29 10:44:45   Using NetVlad network
2022-01-29 10:44:47   using Adam optimizer
2022-01-29 10:44:47   Output dimension of the model is 16384
2022-01-29 10:44:54   Patience: 3
2022-01-29 10:44:54   not improved num: 0
2022-01-29 10:44:54   Start training epoch: 01
2022-01-29 10:44:54   Cache: 0 / 5
2022-01-29 10:57:00   Epoch[01](0/5): current batch triplet loss = 0.0519, average epoch triplet loss = 0.0663
2022-01-29 10:57:00   Cache: 1 / 5
2022-01-29 11:09:02   Epoch[01](1/5): current batch triplet loss = 0.0801, average epoch triplet loss = 0.0645
2022-01-29 11:09:02   Cache: 2 / 5
2022-01-29 11:21:07   Epoch[01](2/5): current batch triplet loss = 0.0946, average epoch triplet loss = 0.0638
2022-01-29 11:21:07   Cache: 3 / 5
2022-01-29 11:33:08   Epoch[01](3/5): current batch triplet loss = 0.0821, average epoch triplet loss = 0.0635
2022-01-29 11:33:08   Cache: 4 / 5
2022-01-29 11:45:12   Epoch[01](4/5): current batch triplet loss = 0.0321, average epoch triplet loss = 0.0624
2022-01-29 11:45:12   Finished epoch 01 in 1:00:18, average epoch triplet loss = 0.0624
2022-01-29 11:45:12   Extracting database features for evaluation/testing
2022-01-29 11:48:58   Extracting queries features for evaluation/testing
2022-01-29 11:51:56   Calculating recalls
2022-01-29 11:52:39   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 83.0, R@5: 93.2, R@10: 95.8, R@20: 97.6
2022-01-29 11:52:39   Improved: previous best R@5 = 92.1, current R@5 = 93.2
2022-01-29 11:52:40   Start training epoch: 02
2022-01-29 11:52:40   Cache: 0 / 5
2022-01-29 12:05:30   Epoch[02](0/5): current batch triplet loss = 0.0679, average epoch triplet loss = 0.0619
2022-01-29 12:05:30   Cache: 1 / 5
2022-01-29 12:17:34   Epoch[02](1/5): current batch triplet loss = 0.0212, average epoch triplet loss = 0.0624
2022-01-29 12:17:34   Cache: 2 / 5
2022-01-29 12:29:37   Epoch[02](2/5): current batch triplet loss = 0.0756, average epoch triplet loss = 0.0616
2022-01-29 12:29:37   Cache: 3 / 5
2022-01-29 12:41:40   Epoch[02](3/5): current batch triplet loss = 0.0498, average epoch triplet loss = 0.0614
2022-01-29 12:41:40   Cache: 4 / 5
2022-01-29 12:53:46   Epoch[02](4/5): current batch triplet loss = 0.0849, average epoch triplet loss = 0.0612
2022-01-29 12:53:46   Finished epoch 02 in 1:01:06, average epoch triplet loss = 0.0612
2022-01-29 12:53:46   Extracting database features for evaluation/testing
2022-01-29 12:57:04   Extracting queries features for evaluation/testing
2022-01-29 12:59:37   Calculating recalls
2022-01-29 13:00:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 84.6, R@5: 93.7, R@10: 96.1, R@20: 97.7
2022-01-29 13:00:19   Improved: previous best R@5 = 93.2, current R@5 = 93.7
2022-01-29 13:00:19   Start training epoch: 03
2022-01-29 13:00:19   Cache: 0 / 5
2022-01-29 13:14:27   Epoch[03](0/5): current batch triplet loss = 0.0504, average epoch triplet loss = 0.0584
2022-01-29 13:14:27   Cache: 1 / 5
2022-01-29 13:26:32   Epoch[03](1/5): current batch triplet loss = 0.0294, average epoch triplet loss = 0.0595
2022-01-29 13:26:32   Cache: 2 / 5
2022-01-29 13:38:37   Epoch[03](2/5): current batch triplet loss = 0.0235, average epoch triplet loss = 0.0586
2022-01-29 13:38:37   Cache: 3 / 5
2022-01-29 13:50:44   Epoch[03](3/5): current batch triplet loss = 0.0471, average epoch triplet loss = 0.0583
2022-01-29 13:50:44   Cache: 4 / 5
2022-01-29 14:02:50   Epoch[03](4/5): current batch triplet loss = 0.0280, average epoch triplet loss = 0.0579
2022-01-29 14:02:50   Finished epoch 03 in 1:02:31, average epoch triplet loss = 0.0579
2022-01-29 14:02:50   Extracting database features for evaluation/testing
2022-01-29 14:06:10   Extracting queries features for evaluation/testing
2022-01-29 14:08:42   Calculating recalls
2022-01-29 14:09:23   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 84.8, R@5: 93.8, R@10: 96.0, R@20: 97.6
2022-01-29 14:09:23   Improved: previous best R@5 = 93.7, current R@5 = 93.8
2022-01-29 14:09:24   Start training epoch: 04
2022-01-29 14:09:24   Cache: 0 / 5
2022-01-29 14:23:37   Epoch[04](0/5): current batch triplet loss = 0.0248, average epoch triplet loss = 0.0578
2022-01-29 14:23:37   Cache: 1 / 5
2022-01-29 14:47:23   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='Netvlad_B-GS-R', data_aug='B-GS-R', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/Netvlad_B-GS-R', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-29 14:47:24   The outputs are being saved in drive/MyDrive/Netvlad_B-GS-R
2022-01-29 14:47:24   Using 1 GPUs and 2 CPUs
2022-01-29 14:47:24   Loading dataset Pitts30k from folder /content/
2022-01-29 14:47:25   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-29 14:47:25   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-29 14:47:25   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-29 14:47:25   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-29 14:47:25   Using NetVlad network
2022-01-29 14:47:27   using Adam optimizer
2022-01-29 14:47:27   Output dimension of the model is 16384
2022-01-29 14:47:32   Patience: 3
2022-01-29 14:47:32   not improved num: 0
2022-01-29 14:47:32   Start training epoch: 04
2022-01-29 14:47:32   Cache: 0 / 5
2022-01-29 15:00:05   Epoch[04](0/5): current batch triplet loss = 0.0432, average epoch triplet loss = 0.0475
2022-01-29 15:00:05   Cache: 1 / 5
2022-01-29 15:12:36   Epoch[04](1/5): current batch triplet loss = 0.0492, average epoch triplet loss = 0.0470
2022-01-29 15:12:36   Cache: 2 / 5
2022-01-29 15:25:12   Epoch[04](2/5): current batch triplet loss = 0.0648, average epoch triplet loss = 0.0465
2022-01-29 15:25:12   Cache: 3 / 5
2022-01-29 15:37:48   Epoch[04](3/5): current batch triplet loss = 0.0751, average epoch triplet loss = 0.0468
2022-01-29 15:37:48   Cache: 4 / 5
2022-01-29 15:50:27   Epoch[04](4/5): current batch triplet loss = 0.0232, average epoch triplet loss = 0.0464
2022-01-29 15:50:27   Finished epoch 04 in 1:02:55, average epoch triplet loss = 0.0464
2022-01-29 15:50:27   Extracting database features for evaluation/testing
2022-01-29 15:53:58   Extracting queries features for evaluation/testing
2022-01-29 15:56:39   Calculating recalls
2022-01-29 15:57:23   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 83.9, R@5: 93.6, R@10: 95.9, R@20: 97.5
2022-01-29 15:57:23   Not improved: 1 / 3: best R@5 = 93.8, current R@5 = 93.6
2022-01-29 15:57:24   Start training epoch: 05
2022-01-29 15:57:24   Cache: 0 / 5
2022-01-29 16:11:15   Epoch[05](0/5): current batch triplet loss = 0.0558, average epoch triplet loss = 0.0470
2022-01-29 16:11:15   Cache: 1 / 5
2022-01-29 16:24:19   Epoch[05](1/5): current batch triplet loss = 0.0122, average epoch triplet loss = 0.0473
2022-01-29 16:24:19   Cache: 2 / 5
2022-01-29 16:37:11   Epoch[05](2/5): current batch triplet loss = 0.0498, average epoch triplet loss = 0.0470
2022-01-29 16:37:11   Cache: 3 / 5
2022-01-29 16:50:14   Epoch[05](3/5): current batch triplet loss = 0.0271, average epoch triplet loss = 0.0471
2022-01-29 16:50:14   Cache: 4 / 5
2022-01-29 17:03:26   Epoch[05](4/5): current batch triplet loss = 0.0591, average epoch triplet loss = 0.0468
2022-01-29 17:03:26   Finished epoch 05 in 1:06:02, average epoch triplet loss = 0.0468
2022-01-29 17:03:26   Extracting database features for evaluation/testing
2022-01-29 17:06:58   Extracting queries features for evaluation/testing
2022-01-29 17:09:39   Calculating recalls
2022-01-29 17:10:21   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 84.5, R@5: 93.6, R@10: 96.0, R@20: 97.6
2022-01-29 17:10:21   Not improved: 2 / 3: best R@5 = 93.8, current R@5 = 93.6
2022-01-29 17:10:22   Start training epoch: 06
2022-01-29 17:10:22   Cache: 0 / 5
2022-01-29 17:23:47   Epoch[06](0/5): current batch triplet loss = 0.0354, average epoch triplet loss = 0.0456
2022-01-29 17:23:47   Cache: 1 / 5
2022-01-30 12:16:49   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='Netvlad_B-GS-R', data_aug='B-GS-R', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/Netvlad_B-GS-R', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-30 12:16:50   
Traceback (most recent call last):
  File "project_vg/train.py", line 63, in <module>
    logging.info(f"Arguments: {args}")
  File "/usr/lib/python3.7/logging/__init__.py", line 1992, in info
    root.info(msg, *args, **kwargs)
  File "/usr/lib/python3.7/logging/__init__.py", line 1378, in info
    self._log(INFO, msg, args, **kwargs)
  File "/usr/lib/python3.7/logging/__init__.py", line 1514, in _log
    self.handle(record)
  File "/usr/lib/python3.7/logging/__init__.py", line 1524, in handle
    self.callHandlers(record)
  File "/usr/lib/python3.7/logging/__init__.py", line 1586, in callHandlers
    hdlr.handle(record)
  File "/usr/lib/python3.7/logging/__init__.py", line 894, in handle
    self.emit(record)
  File "/usr/lib/python3.7/logging/__init__.py", line 1127, in emit
    StreamHandler.emit(self, record)
  File "/usr/lib/python3.7/logging/__init__.py", line 1029, in emit
    self.flush()
  File "/usr/lib/python3.7/logging/__init__.py", line 1009, in flush
    self.stream.flush()
KeyboardInterrupt

2022-01-30 12:17:02   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='Netvlad_B-GS-R', data_aug='B-GS-R', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/Netvlad_B-GS-R', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='NETVLAD', val_positive_dist_threshold=25)
2022-01-30 12:17:02   The outputs are being saved in drive/MyDrive/Netvlad_B-GS-R
2022-01-30 12:17:02   Using 1 GPUs and 2 CPUs
2022-01-30 12:17:02   Loading dataset Pitts30k from folder /content/
2022-01-30 12:17:02   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-30 12:17:02   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-30 12:17:02   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-30 12:17:03   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-30 12:17:03   Using NetVlad network
2022-01-30 12:17:05   using Adam optimizer
2022-01-30 12:17:05   Output dimension of the model is 16384
2022-01-30 12:17:05   Patience: 3
2022-01-30 12:17:05   not improved num: 2
2022-01-30 12:17:05   Start training epoch: 06
2022-01-30 12:17:05   Cache: 0 / 5
2022-01-30 12:29:44   Epoch[06](0/5): current batch triplet loss = 0.0350, average epoch triplet loss = 0.0384
2022-01-30 12:29:44   Cache: 1 / 5
2022-01-30 12:42:27   Epoch[06](1/5): current batch triplet loss = 0.0332, average epoch triplet loss = 0.0382
2022-01-30 12:42:27   Cache: 2 / 5
2022-01-30 12:55:07   Epoch[06](2/5): current batch triplet loss = 0.0497, average epoch triplet loss = 0.0378
2022-01-30 12:55:07   Cache: 3 / 5
2022-01-30 13:07:47   Epoch[06](3/5): current batch triplet loss = 0.0569, average epoch triplet loss = 0.0381
2022-01-30 13:07:47   Cache: 4 / 5
2022-01-30 13:20:25   Epoch[06](4/5): current batch triplet loss = 0.0130, average epoch triplet loss = 0.0380
2022-01-30 13:20:25   Finished epoch 06 in 1:03:19, average epoch triplet loss = 0.0380
2022-01-30 13:20:25   Extracting database features for evaluation/testing
2022-01-30 13:23:56   Extracting queries features for evaluation/testing
2022-01-30 13:26:37   Calculating recalls
2022-01-30 13:27:18   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 83.3, R@5: 93.4, R@10: 95.7, R@20: 97.3
2022-01-30 13:27:18   Not improved: 3 / 3: best R@5 = 93.8, current R@5 = 93.4
2022-01-30 13:27:19   Performance did not improve for 3 epochs. Stop training.
2022-01-30 13:27:19   Best R@5: 93.8
2022-01-30 13:27:19   Trained for 07 epochs, in total in 1:10:17
2022-01-30 13:27:20   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-30 13:27:20   Extracting database features for evaluation/testing
2022-01-30 13:32:01   Extracting queries features for evaluation/testing
2022-01-30 13:35:21   Calculating recalls
2022-01-30 13:35:59   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 82.6, R@5: 91.5, R@10: 94.2, R@20: 96.1
2022-01-30 13:35:59   Test set: < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >
2022-01-30 13:35:59   Extracting database features for evaluation/testing
2022-01-30 13:36:40   Extracting queries features for evaluation/testing
2022-01-30 13:37:16   Calculating recalls
2022-01-30 13:37:18   Recalls on < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >: R@1: 50.7, R@5: 64.4, R@10: 70.6, R@20: 77.4
