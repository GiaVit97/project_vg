2022-01-23 10:32:18   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-23 10:32:18   The outputs are being saved in drive/MyDrive/gem_training
2022-01-23 10:32:18   Using 1 GPUs and 2 CPUs
2022-01-23 10:32:19   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-23 10:32:19   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-23 10:32:19   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-23 10:32:19   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-23 10:32:22   Output dimension of the model is 256
2022-01-23 10:32:22   Start training epoch: 00
2022-01-23 11:10:50   Finished epoch 00 in 0:38:27, average epoch triplet loss = 0.0558
2022-01-23 11:15:37   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 68.2, R@5: 85.0, R@10: 90.0, R@20: 93.7
2022-01-23 11:15:37   Improved: previous best R@5 = 0.0, current R@5 = 85.0
2022-01-23 11:15:37   Start training epoch: 01
2022-01-23 11:54:09   Finished epoch 01 in 0:38:32, average epoch triplet loss = 0.0426
2022-01-23 11:58:57   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 71.8, R@5: 87.3, R@10: 91.5, R@20: 94.7
2022-01-23 11:58:57   Improved: previous best R@5 = 85.0, current R@5 = 87.3
2022-01-23 11:58:57   Start training epoch: 02
2022-01-23 12:37:31   Finished epoch 02 in 0:38:33, average epoch triplet loss = 0.0347
2022-01-23 12:42:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 74.2, R@5: 88.6, R@10: 92.4, R@20: 95.3
2022-01-23 12:42:19   Improved: previous best R@5 = 87.3, current R@5 = 88.6
2022-01-23 12:42:19   Start training epoch: 03
2022-01-23 13:20:41   Finished epoch 03 in 0:38:21, average epoch triplet loss = 0.0307
2022-01-23 14:01:30   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-23 14:01:31   The outputs are being saved in drive/MyDrive/gem_training
2022-01-23 14:01:31   Using 1 GPUs and 2 CPUs
2022-01-23 14:01:31   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-23 14:01:31   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-23 14:01:32   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-23 14:01:32   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-23 14:01:36   Output dimension of the model is 256
2022-01-23 14:01:40   Start training epoch: 03
2022-01-23 14:43:03   Finished epoch 03 in 0:41:23, average epoch triplet loss = 0.0218
2022-01-23 14:48:10   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 74.7, R@5: 88.5, R@10: 92.4, R@20: 95.4
2022-01-23 14:48:11   Improved: previous best R@5 = 87.3, current R@5 = 88.5
2022-01-23 14:48:11   Start training epoch: 04
2022-01-23 15:29:32   Finished epoch 04 in 0:41:20, average epoch triplet loss = 0.0210
2022-01-23 15:34:38   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.7, R@5: 89.0, R@10: 92.6, R@20: 95.4
2022-01-23 15:34:38   Improved: previous best R@5 = 88.5, current R@5 = 89.0
2022-01-23 15:34:38   Start training epoch: 05
2022-01-23 16:16:01   Finished epoch 05 in 0:41:22, average epoch triplet loss = 0.0187
2022-01-23 16:21:08   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.2, R@10: 92.8, R@20: 95.6
2022-01-23 16:21:08   Improved: previous best R@5 = 89.0, current R@5 = 89.2
2022-01-23 16:21:08   Start training epoch: 06
2022-01-23 17:02:22   Finished epoch 06 in 0:41:13, average epoch triplet loss = 0.0191
2022-01-23 17:07:28   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.4, R@5: 89.7, R@10: 93.3, R@20: 95.8
2022-01-23 17:07:29   Improved: previous best R@5 = 89.2, current R@5 = 89.7
2022-01-23 17:07:29   Start training epoch: 07
2022-01-23 17:09:27   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-23 17:09:27   The outputs are being saved in drive/MyDrive/gem_training
2022-01-23 17:09:27   Using 1 GPUs and 2 CPUs
2022-01-23 17:09:27   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-23 17:09:27   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-23 17:09:27   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-23 17:09:28   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-23 17:09:33   Output dimension of the model is 256
2022-01-23 17:09:33   Start training epoch: 07
2022-01-24 10:42:55   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-24 10:42:56   The outputs are being saved in drive/MyDrive/gem_training
2022-01-24 10:42:56   Using 1 GPUs and 2 CPUs
2022-01-24 10:42:56   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-24 10:42:56   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-24 10:42:56   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-24 10:42:56   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-24 10:42:59   Output dimension of the model is 256
2022-01-24 10:43:02   Start training epoch: 07
2022-01-24 11:22:20   Finished epoch 07 in 0:39:17, average epoch triplet loss = 0.0094
2022-01-24 11:27:12   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.6, R@10: 92.9, R@20: 95.7
2022-01-24 11:27:13   Improved: previous best R@5 = 89.2, current R@5 = 89.6
2022-01-24 11:27:13   Start training epoch: 08
2022-01-24 12:06:17   Finished epoch 08 in 0:39:04, average epoch triplet loss = 0.0097
2022-01-24 12:11:03   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.6, R@10: 93.0, R@20: 95.6
2022-01-24 12:11:04   Improved: previous best R@5 = 89.6, current R@5 = 89.6
2022-01-24 12:11:04   Start training epoch: 09
2022-01-24 12:49:46   Finished epoch 09 in 0:38:42, average epoch triplet loss = 0.0092
2022-01-24 12:54:31   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.6, R@10: 92.8, R@20: 95.6
2022-01-24 12:54:31   Not improved: 1 / 3: best R@5 = 89.6, current R@5 = 89.6
2022-01-24 12:54:31   Start training epoch: 10
2022-01-24 13:33:22   Finished epoch 10 in 0:38:51, average epoch triplet loss = 0.0098
2022-01-24 13:38:10   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.8, R@10: 93.2, R@20: 95.8
2022-01-24 13:38:11   Improved: previous best R@5 = 89.6, current R@5 = 89.8
2022-01-24 13:38:11   Start training epoch: 11
2022-01-24 14:17:10   Finished epoch 11 in 0:38:59, average epoch triplet loss = 0.0109
2022-01-24 14:21:58   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.7, R@10: 93.0, R@20: 95.8
2022-01-24 14:21:58   Not improved: 1 / 3: best R@5 = 89.8, current R@5 = 89.7
2022-01-24 14:21:58   Start training epoch: 12
2022-01-24 15:00:54   Finished epoch 12 in 0:38:55, average epoch triplet loss = 0.0102
2022-01-24 15:05:44   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.2, R@5: 89.8, R@10: 93.2, R@20: 95.9
2022-01-24 15:05:44   Not improved: 2 / 3: best R@5 = 89.8, current R@5 = 89.8
2022-01-24 15:05:44   Start training epoch: 13
2022-01-24 15:44:30   Finished epoch 13 in 0:38:45, average epoch triplet loss = 0.0102
2022-01-24 15:49:16   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.9, R@10: 93.2, R@20: 95.9
2022-01-24 15:49:16   Improved: previous best R@5 = 89.8, current R@5 = 89.9
2022-01-24 15:49:16   Start training epoch: 14
2022-01-24 16:27:55   Finished epoch 14 in 0:38:38, average epoch triplet loss = 0.0089
2022-01-24 16:32:40   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.2, R@5: 89.9, R@10: 93.2, R@20: 95.8
2022-01-24 16:32:41   Improved: previous best R@5 = 89.9, current R@5 = 89.9
2022-01-24 16:32:41   Start training epoch: 15
2022-01-25 13:26:29   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-25 13:26:29   The outputs are being saved in drive/MyDrive/gem_training
2022-01-25 13:26:29   Using 1 GPUs and 2 CPUs
2022-01-25 13:26:30   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-25 13:26:30   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-25 13:26:30   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-25 13:26:33   Output dimension of the model is 256
2022-01-25 13:26:35   Start training epoch: 15
2022-01-25 14:17:04   Finished epoch 15 in 0:50:29, average epoch triplet loss = 0.0024
2022-01-25 14:23:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.7, R@10: 93.0, R@20: 95.9
2022-01-25 14:23:19   Not improved: 1 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-25 14:23:19   Start training epoch: 16
2022-01-25 15:13:48   Finished epoch 16 in 0:50:29, average epoch triplet loss = 0.0027
2022-01-25 15:20:03   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.9, R@10: 93.0, R@20: 95.9
2022-01-25 15:20:03   Improved: previous best R@5 = 89.9, current R@5 = 89.9
2022-01-25 15:20:04   Start training epoch: 17
2022-01-25 16:10:32   Finished epoch 17 in 0:50:27, average epoch triplet loss = 0.0030
2022-01-25 16:16:47   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.4, R@10: 93.0, R@20: 95.9
2022-01-25 16:16:47   Not improved: 1 / 3: best R@5 = 89.9, current R@5 = 89.4
2022-01-25 16:16:47   Start training epoch: 18
2022-01-25 17:07:14   Finished epoch 18 in 0:50:27, average epoch triplet loss = 0.0035
2022-01-25 17:13:30   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.7, R@10: 93.1, R@20: 95.9
2022-01-25 17:13:30   Not improved: 2 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-25 17:13:30   Start training epoch: 19
2022-01-26 14:35:57   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-26 14:35:58   The outputs are being saved in drive/MyDrive/gem_training
2022-01-26 14:35:58   Using 1 GPUs and 2 CPUs
2022-01-26 14:35:58   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-26 14:35:58   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-26 14:35:59   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-26 14:36:03   Output dimension of the model is 256
2022-01-26 14:36:05   Start training epoch: 17
2022-01-26 14:58:48   Finished epoch 17 in 0:22:43, average epoch triplet loss = 0.0016
2022-01-26 15:02:01   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.7, R@5: 89.7, R@10: 92.9, R@20: 95.8
2022-01-26 15:02:01   Not improved: 1 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-26 15:02:01   Start training epoch: 18
2022-01-26 15:25:00   Finished epoch 18 in 0:22:59, average epoch triplet loss = 0.0018
2022-01-26 15:28:12   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.7, R@10: 93.0, R@20: 96.0
2022-01-26 15:28:12   Not improved: 2 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-26 15:28:12   Start training epoch: 19
2022-01-26 15:51:17   Finished epoch 19 in 0:23:04, average epoch triplet loss = 0.0026
2022-01-26 15:54:25   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.4, R@10: 93.2, R@20: 95.9
2022-01-26 15:54:25   Not improved: 3 / 3: best R@5 = 89.9, current R@5 = 89.4
2022-01-26 15:54:25   Performance did not improve for 3 epochs. Stop training.
2022-01-26 15:54:26   Best R@5: 89.9
2022-01-26 15:54:26   Trained for 20 epochs, in total in 1:18:28
2022-01-26 15:54:27   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-26 15:57:28   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 75.4, R@5: 89.1, R@10: 92.8, R@20: 95.3
2022-01-26 15:57:28   
Traceback (most recent call last):
  File "project_vg/train.py", line 222, in <module>
    test_ds = datasets_ws.BaseDataset(args, args.datasets_folder, test_dataset, "test")
  File "/content/project_vg/datasets_ws.py", line 60, in __init__
    if not os.path.exists(self.dataset_folder): raise FileNotFoundError(f"Folder {self.dataset_folder} does not exist")
FileNotFoundError: Folder /content/st_lucia/images/test does not exist

2022-01-28 21:11:00   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='gem', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/gem', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-28 21:11:00   The outputs are being saved in drive/MyDrive/gem
2022-01-28 21:11:00   Using 1 GPUs and 2 CPUs
2022-01-28 21:11:01   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-28 21:11:01   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-28 21:11:01   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-28 21:11:05   Output dimension of the model is 256
2022-01-28 21:11:06   Best R@5: 89.9
2022-01-28 21:11:06   Trained for 20 epochs, in total in 0:00:06
2022-01-28 21:11:08   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-28 21:14:14   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 75.4, R@5: 89.1, R@10: 92.8, R@20: 95.3
2022-01-28 21:14:14   Test set: < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >
2022-01-28 21:14:51   Recalls on < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >: R@1: 48.9, R@5: 68.3, R@10: 75.1, R@20: 80.6
