2022-01-23 10:32:18   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-23 10:32:18   The outputs are being saved in drive/MyDrive/gem_training
2022-01-23 10:32:18   Using 1 GPUs and 2 CPUs
2022-01-23 10:32:18   Loading dataset Pitts30k from folder /content/
2022-01-23 10:32:19   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-23 10:32:19   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-23 10:32:19   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-23 10:32:19   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-23 10:32:21   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-23 10:32:21   Using GeM network
2022-01-23 10:32:22   Output dimension of the model is 256
2022-01-23 10:32:22   Start training epoch: 00
2022-01-23 10:32:22   Cache: 0 / 5
2022-01-23 10:40:07   Epoch[00](0/5): current batch triplet loss = 0.0686, average epoch triplet loss = 0.0679
2022-01-23 10:40:07   Cache: 1 / 5
2022-01-23 10:47:50   Epoch[00](1/5): current batch triplet loss = 0.0792, average epoch triplet loss = 0.0638
2022-01-23 10:47:50   Cache: 2 / 5
2022-01-23 10:55:31   Epoch[00](2/5): current batch triplet loss = 0.0358, average epoch triplet loss = 0.0603
2022-01-23 10:55:31   Cache: 3 / 5
2022-01-23 11:03:11   Epoch[00](3/5): current batch triplet loss = 0.0704, average epoch triplet loss = 0.0577
2022-01-23 11:03:11   Cache: 4 / 5
2022-01-23 11:10:50   Epoch[00](4/5): current batch triplet loss = 0.0574, average epoch triplet loss = 0.0558
2022-01-23 11:10:50   Finished epoch 00 in 0:38:27, average epoch triplet loss = 0.0558
2022-01-23 11:10:50   Extracting database features for evaluation/testing
2022-01-23 11:13:31   Extracting queries features for evaluation/testing
2022-01-23 11:15:35   Calculating recalls
2022-01-23 11:15:37   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 68.2, R@5: 85.0, R@10: 90.0, R@20: 93.7
2022-01-23 11:15:37   Improved: previous best R@5 = 0.0, current R@5 = 85.0
2022-01-23 11:15:37   Start training epoch: 01
2022-01-23 11:15:37   Cache: 0 / 5
2022-01-23 11:23:19   Epoch[01](0/5): current batch triplet loss = 0.0707, average epoch triplet loss = 0.0454
2022-01-23 11:23:19   Cache: 1 / 5
2022-01-23 11:31:02   Epoch[01](1/5): current batch triplet loss = 0.0338, average epoch triplet loss = 0.0445
2022-01-23 11:31:02   Cache: 2 / 5
2022-01-23 11:38:44   Epoch[01](2/5): current batch triplet loss = 0.0614, average epoch triplet loss = 0.0435
2022-01-23 11:38:44   Cache: 3 / 5
2022-01-23 11:46:27   Epoch[01](3/5): current batch triplet loss = 0.0457, average epoch triplet loss = 0.0432
2022-01-23 11:46:27   Cache: 4 / 5
2022-01-23 11:54:09   Epoch[01](4/5): current batch triplet loss = 0.0465, average epoch triplet loss = 0.0426
2022-01-23 11:54:09   Finished epoch 01 in 0:38:32, average epoch triplet loss = 0.0426
2022-01-23 11:54:09   Extracting database features for evaluation/testing
2022-01-23 11:56:52   Extracting queries features for evaluation/testing
2022-01-23 11:58:55   Calculating recalls
2022-01-23 11:58:57   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 71.8, R@5: 87.3, R@10: 91.5, R@20: 94.7
2022-01-23 11:58:57   Improved: previous best R@5 = 85.0, current R@5 = 87.3
2022-01-23 11:58:57   Start training epoch: 02
2022-01-23 11:58:57   Cache: 0 / 5
2022-01-23 12:06:41   Epoch[02](0/5): current batch triplet loss = 0.0321, average epoch triplet loss = 0.0366
2022-01-23 12:06:41   Cache: 1 / 5
2022-01-23 12:14:20   Epoch[02](1/5): current batch triplet loss = 0.0205, average epoch triplet loss = 0.0364
2022-01-23 12:14:20   Cache: 2 / 5
2022-01-23 12:22:03   Epoch[02](2/5): current batch triplet loss = 0.0184, average epoch triplet loss = 0.0360
2022-01-23 12:22:03   Cache: 3 / 5
2022-01-23 12:29:47   Epoch[02](3/5): current batch triplet loss = 0.0196, average epoch triplet loss = 0.0351
2022-01-23 12:29:47   Cache: 4 / 5
2022-01-23 12:37:31   Epoch[02](4/5): current batch triplet loss = 0.0209, average epoch triplet loss = 0.0347
2022-01-23 12:37:31   Finished epoch 02 in 0:38:33, average epoch triplet loss = 0.0347
2022-01-23 12:37:31   Extracting database features for evaluation/testing
2022-01-23 12:40:13   Extracting queries features for evaluation/testing
2022-01-23 12:42:17   Calculating recalls
2022-01-23 12:42:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 74.2, R@5: 88.6, R@10: 92.4, R@20: 95.3
2022-01-23 12:42:19   Improved: previous best R@5 = 87.3, current R@5 = 88.6
2022-01-23 12:42:19   Start training epoch: 03
2022-01-23 12:42:19   Cache: 0 / 5
2022-01-23 12:50:03   Epoch[03](0/5): current batch triplet loss = 0.0070, average epoch triplet loss = 0.0302
2022-01-23 12:50:03   Cache: 1 / 5
2022-01-23 12:57:46   Epoch[03](1/5): current batch triplet loss = 0.0423, average epoch triplet loss = 0.0312
2022-01-23 12:57:46   Cache: 2 / 5
2022-01-23 13:05:24   Epoch[03](2/5): current batch triplet loss = 0.0280, average epoch triplet loss = 0.0311
2022-01-23 13:05:24   Cache: 3 / 5
2022-01-23 13:13:01   Epoch[03](3/5): current batch triplet loss = 0.0697, average epoch triplet loss = 0.0309
2022-01-23 13:13:01   Cache: 4 / 5
2022-01-23 13:20:41   Epoch[03](4/5): current batch triplet loss = 0.0307, average epoch triplet loss = 0.0307
2022-01-23 13:20:41   Finished epoch 03 in 0:38:21, average epoch triplet loss = 0.0307
2022-01-23 13:20:41   Extracting database features for evaluation/testing
2022-01-23 13:23:22   Extracting queries features for evaluation/testing
2022-01-23 14:01:30   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-23 14:01:31   The outputs are being saved in drive/MyDrive/gem_training
2022-01-23 14:01:31   Using 1 GPUs and 2 CPUs
2022-01-23 14:01:31   Loading dataset Pitts30k from folder /content/
2022-01-23 14:01:31   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-23 14:01:31   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-23 14:01:32   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-23 14:01:32   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-23 14:01:34   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-23 14:01:34   Using GeM network
2022-01-23 14:01:36   Output dimension of the model is 256
2022-01-23 14:01:40   Start training epoch: 03
2022-01-23 14:01:40   Cache: 0 / 5
2022-01-23 14:10:02   Epoch[03](0/5): current batch triplet loss = 0.0236, average epoch triplet loss = 0.0235
2022-01-23 14:10:02   Cache: 1 / 5
2022-01-23 14:18:19   Epoch[03](1/5): current batch triplet loss = 0.0291, average epoch triplet loss = 0.0228
2022-01-23 14:18:19   Cache: 2 / 5
2022-01-23 14:26:35   Epoch[03](2/5): current batch triplet loss = 0.0048, average epoch triplet loss = 0.0222
2022-01-23 14:26:35   Cache: 3 / 5
2022-01-23 14:34:50   Epoch[03](3/5): current batch triplet loss = 0.0387, average epoch triplet loss = 0.0219
2022-01-23 14:34:50   Cache: 4 / 5
2022-01-23 14:43:03   Epoch[03](4/5): current batch triplet loss = 0.0378, average epoch triplet loss = 0.0218
2022-01-23 14:43:03   Finished epoch 03 in 0:41:23, average epoch triplet loss = 0.0218
2022-01-23 14:43:03   Extracting database features for evaluation/testing
2022-01-23 14:45:56   Extracting queries features for evaluation/testing
2022-01-23 14:48:08   Calculating recalls
2022-01-23 14:48:10   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 74.7, R@5: 88.5, R@10: 92.4, R@20: 95.4
2022-01-23 14:48:11   Improved: previous best R@5 = 87.3, current R@5 = 88.5
2022-01-23 14:48:11   Start training epoch: 04
2022-01-23 14:48:11   Cache: 0 / 5
2022-01-23 14:56:27   Epoch[04](0/5): current batch triplet loss = 0.0356, average epoch triplet loss = 0.0210
2022-01-23 14:56:27   Cache: 1 / 5
2022-01-23 15:04:42   Epoch[04](1/5): current batch triplet loss = 0.0230, average epoch triplet loss = 0.0210
2022-01-23 15:04:42   Cache: 2 / 5
2022-01-23 15:12:59   Epoch[04](2/5): current batch triplet loss = 0.0256, average epoch triplet loss = 0.0205
2022-01-23 15:12:59   Cache: 3 / 5
2022-01-23 15:21:19   Epoch[04](3/5): current batch triplet loss = 0.0301, average epoch triplet loss = 0.0209
2022-01-23 15:21:19   Cache: 4 / 5
2022-01-23 15:29:32   Epoch[04](4/5): current batch triplet loss = 0.0229, average epoch triplet loss = 0.0210
2022-01-23 15:29:32   Finished epoch 04 in 0:41:20, average epoch triplet loss = 0.0210
2022-01-23 15:29:32   Extracting database features for evaluation/testing
2022-01-23 15:32:24   Extracting queries features for evaluation/testing
2022-01-23 15:34:37   Calculating recalls
2022-01-23 15:34:38   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.7, R@5: 89.0, R@10: 92.6, R@20: 95.4
2022-01-23 15:34:38   Improved: previous best R@5 = 88.5, current R@5 = 89.0
2022-01-23 15:34:38   Start training epoch: 05
2022-01-23 15:34:38   Cache: 0 / 5
2022-01-23 15:42:56   Epoch[05](0/5): current batch triplet loss = 0.0039, average epoch triplet loss = 0.0188
2022-01-23 15:42:56   Cache: 1 / 5
2022-01-23 15:51:15   Epoch[05](1/5): current batch triplet loss = 0.0098, average epoch triplet loss = 0.0192
2022-01-23 15:51:15   Cache: 2 / 5
2022-01-23 15:59:28   Epoch[05](2/5): current batch triplet loss = 0.0038, average epoch triplet loss = 0.0192
2022-01-23 15:59:28   Cache: 3 / 5
2022-01-23 16:07:42   Epoch[05](3/5): current batch triplet loss = 0.0138, average epoch triplet loss = 0.0188
2022-01-23 16:07:42   Cache: 4 / 5
2022-01-23 16:16:01   Epoch[05](4/5): current batch triplet loss = 0.0074, average epoch triplet loss = 0.0187
2022-01-23 16:16:01   Finished epoch 05 in 0:41:22, average epoch triplet loss = 0.0187
2022-01-23 16:16:01   Extracting database features for evaluation/testing
2022-01-23 16:18:54   Extracting queries features for evaluation/testing
2022-01-23 16:21:06   Calculating recalls
2022-01-23 16:21:08   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.2, R@10: 92.8, R@20: 95.6
2022-01-23 16:21:08   Improved: previous best R@5 = 89.0, current R@5 = 89.2
2022-01-23 16:21:08   Start training epoch: 06
2022-01-23 16:21:08   Cache: 0 / 5
2022-01-23 16:29:22   Epoch[06](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0180
2022-01-23 16:29:22   Cache: 1 / 5
2022-01-23 16:37:40   Epoch[06](1/5): current batch triplet loss = 0.0215, average epoch triplet loss = 0.0192
2022-01-23 16:37:40   Cache: 2 / 5
2022-01-23 16:45:56   Epoch[06](2/5): current batch triplet loss = 0.0202, average epoch triplet loss = 0.0191
2022-01-23 16:45:56   Cache: 3 / 5
2022-01-23 16:54:09   Epoch[06](3/5): current batch triplet loss = 0.0553, average epoch triplet loss = 0.0190
2022-01-23 16:54:09   Cache: 4 / 5
2022-01-23 17:02:22   Epoch[06](4/5): current batch triplet loss = 0.0197, average epoch triplet loss = 0.0191
2022-01-23 17:02:22   Finished epoch 06 in 0:41:13, average epoch triplet loss = 0.0191
2022-01-23 17:02:22   Extracting database features for evaluation/testing
2022-01-23 17:05:15   Extracting queries features for evaluation/testing
2022-01-23 17:07:27   Calculating recalls
2022-01-23 17:07:28   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.4, R@5: 89.7, R@10: 93.3, R@20: 95.8
2022-01-23 17:07:29   Improved: previous best R@5 = 89.2, current R@5 = 89.7
2022-01-23 17:07:29   Start training epoch: 07
2022-01-23 17:07:29   Cache: 0 / 5
2022-01-23 17:09:27   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-23 17:09:27   The outputs are being saved in drive/MyDrive/gem_training
2022-01-23 17:09:27   Using 1 GPUs and 2 CPUs
2022-01-23 17:09:27   Loading dataset Pitts30k from folder /content/
2022-01-23 17:09:27   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-23 17:09:27   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-23 17:09:27   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-23 17:09:28   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-23 17:09:28   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-23 17:09:28   Using GeM network
2022-01-23 17:09:33   Output dimension of the model is 256
2022-01-23 17:09:33   Start training epoch: 07
2022-01-23 17:09:33   Cache: 0 / 5
2022-01-23 17:17:48   Epoch[07](0/5): current batch triplet loss = 0.0176, average epoch triplet loss = 0.0097
2022-01-23 17:17:48   Cache: 1 / 5
2022-01-23 17:26:00   Epoch[07](1/5): current batch triplet loss = 0.0077, average epoch triplet loss = 0.0095
2022-01-23 17:26:00   Cache: 2 / 5
2022-01-23 17:34:12   Epoch[07](2/5): current batch triplet loss = 0.0019, average epoch triplet loss = 0.0093
2022-01-23 17:34:12   Cache: 3 / 5
2022-01-24 10:42:55   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-24 10:42:56   The outputs are being saved in drive/MyDrive/gem_training
2022-01-24 10:42:56   Using 1 GPUs and 2 CPUs
2022-01-24 10:42:56   Loading dataset Pitts30k from folder /content/
2022-01-24 10:42:56   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-24 10:42:56   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-24 10:42:56   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-24 10:42:56   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-24 10:42:57   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-24 10:42:57   Using GeM network
2022-01-24 10:42:59   Output dimension of the model is 256
2022-01-24 10:43:02   Start training epoch: 07
2022-01-24 10:43:02   Cache: 0 / 5
2022-01-24 10:50:54   Epoch[07](0/5): current batch triplet loss = 0.0176, average epoch triplet loss = 0.0097
2022-01-24 10:50:54   Cache: 1 / 5
2022-01-24 10:58:42   Epoch[07](1/5): current batch triplet loss = 0.0077, average epoch triplet loss = 0.0095
2022-01-24 10:58:42   Cache: 2 / 5
2022-01-24 11:06:32   Epoch[07](2/5): current batch triplet loss = 0.0019, average epoch triplet loss = 0.0093
2022-01-24 11:06:32   Cache: 3 / 5
2022-01-24 11:14:25   Epoch[07](3/5): current batch triplet loss = 0.0175, average epoch triplet loss = 0.0093
2022-01-24 11:14:25   Cache: 4 / 5
2022-01-24 11:22:20   Epoch[07](4/5): current batch triplet loss = 0.0213, average epoch triplet loss = 0.0094
2022-01-24 11:22:20   Finished epoch 07 in 0:39:17, average epoch triplet loss = 0.0094
2022-01-24 11:22:20   Extracting database features for evaluation/testing
2022-01-24 11:25:05   Extracting queries features for evaluation/testing
2022-01-24 11:27:11   Calculating recalls
2022-01-24 11:27:12   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.6, R@10: 92.9, R@20: 95.7
2022-01-24 11:27:13   Improved: previous best R@5 = 89.2, current R@5 = 89.6
2022-01-24 11:27:13   Start training epoch: 08
2022-01-24 11:27:13   Cache: 0 / 5
2022-01-24 11:35:07   Epoch[08](0/5): current batch triplet loss = 0.0112, average epoch triplet loss = 0.0098
2022-01-24 11:35:07   Cache: 1 / 5
2022-01-24 11:42:56   Epoch[08](1/5): current batch triplet loss = 0.0129, average epoch triplet loss = 0.0097
2022-01-24 11:42:56   Cache: 2 / 5
2022-01-24 11:50:46   Epoch[08](2/5): current batch triplet loss = 0.0107, average epoch triplet loss = 0.0092
2022-01-24 11:50:46   Cache: 3 / 5
2022-01-24 11:58:35   Epoch[08](3/5): current batch triplet loss = 0.0174, average epoch triplet loss = 0.0095
2022-01-24 11:58:35   Cache: 4 / 5
2022-01-24 12:06:17   Epoch[08](4/5): current batch triplet loss = 0.0156, average epoch triplet loss = 0.0097
2022-01-24 12:06:17   Finished epoch 08 in 0:39:04, average epoch triplet loss = 0.0097
2022-01-24 12:06:17   Extracting database features for evaluation/testing
2022-01-24 12:08:59   Extracting queries features for evaluation/testing
2022-01-24 12:11:02   Calculating recalls
2022-01-24 12:11:03   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.6, R@10: 93.0, R@20: 95.6
2022-01-24 12:11:04   Improved: previous best R@5 = 89.6, current R@5 = 89.6
2022-01-24 12:11:04   Start training epoch: 09
2022-01-24 12:11:04   Cache: 0 / 5
2022-01-24 12:18:49   Epoch[09](0/5): current batch triplet loss = 0.0010, average epoch triplet loss = 0.0090
2022-01-24 12:18:49   Cache: 1 / 5
2022-01-24 12:26:33   Epoch[09](1/5): current batch triplet loss = 0.0069, average epoch triplet loss = 0.0093
2022-01-24 12:26:33   Cache: 2 / 5
2022-01-24 12:34:15   Epoch[09](2/5): current batch triplet loss = 0.0015, average epoch triplet loss = 0.0094
2022-01-24 12:34:15   Cache: 3 / 5
2022-01-24 12:42:00   Epoch[09](3/5): current batch triplet loss = 0.0086, average epoch triplet loss = 0.0094
2022-01-24 12:42:00   Cache: 4 / 5
2022-01-24 12:49:46   Epoch[09](4/5): current batch triplet loss = 0.0030, average epoch triplet loss = 0.0092
2022-01-24 12:49:46   Finished epoch 09 in 0:38:42, average epoch triplet loss = 0.0092
2022-01-24 12:49:46   Extracting database features for evaluation/testing
2022-01-24 12:52:26   Extracting queries features for evaluation/testing
2022-01-24 12:54:30   Calculating recalls
2022-01-24 12:54:31   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.6, R@10: 92.8, R@20: 95.6
2022-01-24 12:54:31   Not improved: 1 / 3: best R@5 = 89.6, current R@5 = 89.6
2022-01-24 12:54:31   Start training epoch: 10
2022-01-24 12:54:31   Cache: 0 / 5
2022-01-24 13:02:17   Epoch[10](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0094
2022-01-24 13:02:17   Cache: 1 / 5
2022-01-24 13:10:02   Epoch[10](1/5): current batch triplet loss = 0.0085, average epoch triplet loss = 0.0099
2022-01-24 13:10:02   Cache: 2 / 5
2022-01-24 13:17:45   Epoch[10](2/5): current batch triplet loss = 0.0075, average epoch triplet loss = 0.0099
2022-01-24 13:17:45   Cache: 3 / 5
2022-01-24 13:25:35   Epoch[10](3/5): current batch triplet loss = 0.0342, average epoch triplet loss = 0.0098
2022-01-24 13:25:35   Cache: 4 / 5
2022-01-24 13:33:22   Epoch[10](4/5): current batch triplet loss = 0.0107, average epoch triplet loss = 0.0098
2022-01-24 13:33:22   Finished epoch 10 in 0:38:51, average epoch triplet loss = 0.0098
2022-01-24 13:33:22   Extracting database features for evaluation/testing
2022-01-24 13:36:05   Extracting queries features for evaluation/testing
2022-01-24 13:38:09   Calculating recalls
2022-01-24 13:38:10   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.8, R@10: 93.2, R@20: 95.8
2022-01-24 13:38:11   Improved: previous best R@5 = 89.6, current R@5 = 89.8
2022-01-24 13:38:11   Start training epoch: 11
2022-01-24 13:38:11   Cache: 0 / 5
2022-01-24 13:45:57   Epoch[11](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0111
2022-01-24 13:45:57   Cache: 1 / 5
2022-01-24 13:53:44   Epoch[11](1/5): current batch triplet loss = 0.0089, average epoch triplet loss = 0.0107
2022-01-24 13:53:44   Cache: 2 / 5
2022-01-24 14:01:32   Epoch[11](2/5): current batch triplet loss = 0.0319, average epoch triplet loss = 0.0107
2022-01-24 14:01:32   Cache: 3 / 5
2022-01-24 14:09:23   Epoch[11](3/5): current batch triplet loss = 0.0079, average epoch triplet loss = 0.0109
2022-01-24 14:09:23   Cache: 4 / 5
2022-01-24 14:17:10   Epoch[11](4/5): current batch triplet loss = 0.0010, average epoch triplet loss = 0.0109
2022-01-24 14:17:10   Finished epoch 11 in 0:38:59, average epoch triplet loss = 0.0109
2022-01-24 14:17:10   Extracting database features for evaluation/testing
2022-01-24 14:19:53   Extracting queries features for evaluation/testing
2022-01-24 14:21:57   Calculating recalls
2022-01-24 14:21:58   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.7, R@10: 93.0, R@20: 95.8
2022-01-24 14:21:58   Not improved: 1 / 3: best R@5 = 89.8, current R@5 = 89.7
2022-01-24 14:21:58   Start training epoch: 12
2022-01-24 14:21:58   Cache: 0 / 5
2022-01-24 14:29:47   Epoch[12](0/5): current batch triplet loss = 0.0138, average epoch triplet loss = 0.0106
2022-01-24 14:29:47   Cache: 1 / 5
2022-01-24 14:37:37   Epoch[12](1/5): current batch triplet loss = 0.0028, average epoch triplet loss = 0.0099
2022-01-24 14:37:37   Cache: 2 / 5
2022-01-24 14:45:22   Epoch[12](2/5): current batch triplet loss = 0.0063, average epoch triplet loss = 0.0101
2022-01-24 14:45:22   Cache: 3 / 5
2022-01-24 14:53:06   Epoch[12](3/5): current batch triplet loss = 0.0022, average epoch triplet loss = 0.0102
2022-01-24 14:53:06   Cache: 4 / 5
2022-01-24 15:00:54   Epoch[12](4/5): current batch triplet loss = 0.0143, average epoch triplet loss = 0.0102
2022-01-24 15:00:54   Finished epoch 12 in 0:38:55, average epoch triplet loss = 0.0102
2022-01-24 15:00:54   Extracting database features for evaluation/testing
2022-01-24 15:03:38   Extracting queries features for evaluation/testing
2022-01-24 15:05:43   Calculating recalls
2022-01-24 15:05:44   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.2, R@5: 89.8, R@10: 93.2, R@20: 95.9
2022-01-24 15:05:44   Not improved: 2 / 3: best R@5 = 89.8, current R@5 = 89.8
2022-01-24 15:05:44   Start training epoch: 13
2022-01-24 15:05:44   Cache: 0 / 5
2022-01-24 15:13:30   Epoch[13](0/5): current batch triplet loss = 0.0325, average epoch triplet loss = 0.0111
2022-01-24 15:13:30   Cache: 1 / 5
2022-01-24 15:21:14   Epoch[13](1/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0103
2022-01-24 15:21:14   Cache: 2 / 5
2022-01-24 15:28:58   Epoch[13](2/5): current batch triplet loss = 0.0072, average epoch triplet loss = 0.0101
2022-01-24 15:28:58   Cache: 3 / 5
2022-01-24 15:36:47   Epoch[13](3/5): current batch triplet loss = 0.0107, average epoch triplet loss = 0.0101
2022-01-24 15:36:47   Cache: 4 / 5
2022-01-24 15:44:30   Epoch[13](4/5): current batch triplet loss = 0.0055, average epoch triplet loss = 0.0102
2022-01-24 15:44:30   Finished epoch 13 in 0:38:45, average epoch triplet loss = 0.0102
2022-01-24 15:44:30   Extracting database features for evaluation/testing
2022-01-24 15:47:11   Extracting queries features for evaluation/testing
2022-01-24 15:49:14   Calculating recalls
2022-01-24 15:49:16   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.9, R@10: 93.2, R@20: 95.9
2022-01-24 15:49:16   Improved: previous best R@5 = 89.8, current R@5 = 89.9
2022-01-24 15:49:16   Start training epoch: 14
2022-01-24 15:49:16   Cache: 0 / 5
2022-01-24 15:56:59   Epoch[14](0/5): current batch triplet loss = 0.0054, average epoch triplet loss = 0.0096
2022-01-24 15:56:59   Cache: 1 / 5
2022-01-24 16:04:41   Epoch[14](1/5): current batch triplet loss = 0.0088, average epoch triplet loss = 0.0090
2022-01-24 16:04:41   Cache: 2 / 5
2022-01-24 16:12:24   Epoch[14](2/5): current batch triplet loss = 0.0133, average epoch triplet loss = 0.0092
2022-01-24 16:12:24   Cache: 3 / 5
2022-01-24 16:20:08   Epoch[14](3/5): current batch triplet loss = 0.0079, average epoch triplet loss = 0.0091
2022-01-24 16:20:08   Cache: 4 / 5
2022-01-24 16:27:55   Epoch[14](4/5): current batch triplet loss = 0.0015, average epoch triplet loss = 0.0089
2022-01-24 16:27:55   Finished epoch 14 in 0:38:38, average epoch triplet loss = 0.0089
2022-01-24 16:27:55   Extracting database features for evaluation/testing
2022-01-24 16:30:36   Extracting queries features for evaluation/testing
2022-01-24 16:32:39   Calculating recalls
2022-01-24 16:32:40   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.2, R@5: 89.9, R@10: 93.2, R@20: 95.8
2022-01-24 16:32:41   Improved: previous best R@5 = 89.9, current R@5 = 89.9
2022-01-24 16:32:41   Start training epoch: 15
2022-01-24 16:32:41   Cache: 0 / 5
2022-01-25 13:26:29   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-25 13:26:29   The outputs are being saved in drive/MyDrive/gem_training
2022-01-25 13:26:29   Using 1 GPUs and 2 CPUs
2022-01-25 13:26:29   Loading dataset Pitts30k from folder /content/
2022-01-25 13:26:30   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-25 13:26:30   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-25 13:26:30   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-25 13:26:31   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-25 13:26:31   Using GeM network
2022-01-25 13:26:33   Output dimension of the model is 256
2022-01-25 13:26:35   Patience: 3
2022-01-25 13:26:35   not improved num: 0
2022-01-25 13:26:35   Start training epoch: 15
2022-01-25 13:26:35   Cache: 0 / 5
2022-01-25 13:36:45   Epoch[15](0/5): current batch triplet loss = 0.0054, average epoch triplet loss = 0.0023
2022-01-25 13:36:45   Cache: 1 / 5
2022-01-25 13:46:51   Epoch[15](1/5): current batch triplet loss = 0.0031, average epoch triplet loss = 0.0023
2022-01-25 13:46:51   Cache: 2 / 5
2022-01-25 13:56:56   Epoch[15](2/5): current batch triplet loss = 0.0009, average epoch triplet loss = 0.0023
2022-01-25 13:56:56   Cache: 3 / 5
2022-01-25 14:07:01   Epoch[15](3/5): current batch triplet loss = 0.0015, average epoch triplet loss = 0.0023
2022-01-25 14:07:01   Cache: 4 / 5
2022-01-25 14:17:04   Epoch[15](4/5): current batch triplet loss = 0.0058, average epoch triplet loss = 0.0024
2022-01-25 14:17:04   Finished epoch 15 in 0:50:29, average epoch triplet loss = 0.0024
2022-01-25 14:17:04   Extracting database features for evaluation/testing
2022-01-25 14:20:36   Extracting queries features for evaluation/testing
2022-01-25 14:23:17   Calculating recalls
2022-01-25 14:23:19   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.7, R@10: 93.0, R@20: 95.9
2022-01-25 14:23:19   Not improved: 1 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-25 14:23:19   Start training epoch: 16
2022-01-25 14:23:19   Cache: 0 / 5
2022-01-25 14:33:25   Epoch[16](0/5): current batch triplet loss = 0.0034, average epoch triplet loss = 0.0027
2022-01-25 14:33:25   Cache: 1 / 5
2022-01-25 14:43:31   Epoch[16](1/5): current batch triplet loss = 0.0047, average epoch triplet loss = 0.0027
2022-01-25 14:43:31   Cache: 2 / 5
2022-01-25 14:53:39   Epoch[16](2/5): current batch triplet loss = 0.0021, average epoch triplet loss = 0.0025
2022-01-25 14:53:39   Cache: 3 / 5
2022-01-25 15:03:42   Epoch[16](3/5): current batch triplet loss = 0.0094, average epoch triplet loss = 0.0026
2022-01-25 15:03:42   Cache: 4 / 5
2022-01-25 15:13:48   Epoch[16](4/5): current batch triplet loss = 0.0074, average epoch triplet loss = 0.0027
2022-01-25 15:13:48   Finished epoch 16 in 0:50:29, average epoch triplet loss = 0.0027
2022-01-25 15:13:48   Extracting database features for evaluation/testing
2022-01-25 15:17:20   Extracting queries features for evaluation/testing
2022-01-25 15:20:02   Calculating recalls
2022-01-25 15:20:03   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.9, R@10: 93.0, R@20: 95.9
2022-01-25 15:20:03   Improved: previous best R@5 = 89.9, current R@5 = 89.9
2022-01-25 15:20:04   Start training epoch: 17
2022-01-25 15:20:04   Cache: 0 / 5
2022-01-25 15:30:09   Epoch[17](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0029
2022-01-25 15:30:09   Cache: 1 / 5
2022-01-25 15:40:14   Epoch[17](1/5): current batch triplet loss = 0.0052, average epoch triplet loss = 0.0030
2022-01-25 15:40:14   Cache: 2 / 5
2022-01-25 15:50:22   Epoch[17](2/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0031
2022-01-25 15:50:22   Cache: 3 / 5
2022-01-25 16:00:27   Epoch[17](3/5): current batch triplet loss = 0.0046, average epoch triplet loss = 0.0031
2022-01-25 16:00:27   Cache: 4 / 5
2022-01-25 16:10:32   Epoch[17](4/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0030
2022-01-25 16:10:32   Finished epoch 17 in 0:50:27, average epoch triplet loss = 0.0030
2022-01-25 16:10:32   Extracting database features for evaluation/testing
2022-01-25 16:14:04   Extracting queries features for evaluation/testing
2022-01-25 16:16:45   Calculating recalls
2022-01-25 16:16:47   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.9, R@5: 89.4, R@10: 93.0, R@20: 95.9
2022-01-25 16:16:47   Not improved: 1 / 3: best R@5 = 89.9, current R@5 = 89.4
2022-01-25 16:16:47   Start training epoch: 18
2022-01-25 16:16:47   Cache: 0 / 5
2022-01-25 16:26:54   Epoch[18](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0035
2022-01-25 16:26:54   Cache: 1 / 5
2022-01-25 16:36:59   Epoch[18](1/5): current batch triplet loss = 0.0031, average epoch triplet loss = 0.0035
2022-01-25 16:36:59   Cache: 2 / 5
2022-01-25 16:47:03   Epoch[18](2/5): current batch triplet loss = 0.0025, average epoch triplet loss = 0.0035
2022-01-25 16:47:03   Cache: 3 / 5
2022-01-25 16:57:08   Epoch[18](3/5): current batch triplet loss = 0.0041, average epoch triplet loss = 0.0035
2022-01-25 16:57:08   Cache: 4 / 5
2022-01-25 17:07:14   Epoch[18](4/5): current batch triplet loss = 0.0055, average epoch triplet loss = 0.0035
2022-01-25 17:07:14   Finished epoch 18 in 0:50:27, average epoch triplet loss = 0.0035
2022-01-25 17:07:14   Extracting database features for evaluation/testing
2022-01-25 17:10:47   Extracting queries features for evaluation/testing
2022-01-25 17:13:29   Calculating recalls
2022-01-25 17:13:30   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.7, R@10: 93.1, R@20: 95.9
2022-01-25 17:13:30   Not improved: 2 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-25 17:13:30   Start training epoch: 19
2022-01-25 17:13:30   Cache: 0 / 5
2022-01-25 17:23:39   Epoch[19](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0036
2022-01-25 17:23:39   Cache: 1 / 5
2022-01-25 17:33:43   Epoch[19](1/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0037
2022-01-25 17:33:43   Cache: 2 / 5
2022-01-25 17:43:48   Epoch[19](2/5): current batch triplet loss = 0.0049, average epoch triplet loss = 0.0038
2022-01-25 17:43:48   Cache: 3 / 5
2022-01-26 14:35:57   Arguments: Namespace(cache_refresh_rate=1000, colab_folder='gem_training', dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, output_folder='drive/MyDrive/gem_training', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-26 14:35:58   The outputs are being saved in drive/MyDrive/gem_training
2022-01-26 14:35:58   Using 1 GPUs and 2 CPUs
2022-01-26 14:35:58   Loading dataset Pitts30k from folder /content/
2022-01-26 14:35:58   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-26 14:35:58   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-26 14:35:59   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-26 14:36:00   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-26 14:36:00   Using GeM network
2022-01-26 14:36:03   Output dimension of the model is 256
2022-01-26 14:36:05   Patience: 3
2022-01-26 14:36:05   not improved num: 0
2022-01-26 14:36:05   Start training epoch: 17
2022-01-26 14:36:05   Cache: 0 / 5
2022-01-26 14:40:36   Epoch[17](0/5): current batch triplet loss = 0.0041, average epoch triplet loss = 0.0015
2022-01-26 14:40:36   Cache: 1 / 5
2022-01-26 14:45:09   Epoch[17](1/5): current batch triplet loss = 0.0031, average epoch triplet loss = 0.0015
2022-01-26 14:45:09   Cache: 2 / 5
2022-01-26 14:49:41   Epoch[17](2/5): current batch triplet loss = 0.0001, average epoch triplet loss = 0.0015
2022-01-26 14:49:41   Cache: 3 / 5
2022-01-26 14:54:15   Epoch[17](3/5): current batch triplet loss = 0.0005, average epoch triplet loss = 0.0015
2022-01-26 14:54:15   Cache: 4 / 5
2022-01-26 14:58:48   Epoch[17](4/5): current batch triplet loss = 0.0042, average epoch triplet loss = 0.0016
2022-01-26 14:58:48   Finished epoch 17 in 0:22:43, average epoch triplet loss = 0.0016
2022-01-26 14:58:48   Extracting database features for evaluation/testing
2022-01-26 15:00:37   Extracting queries features for evaluation/testing
2022-01-26 15:01:59   Calculating recalls
2022-01-26 15:02:01   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.7, R@5: 89.7, R@10: 92.9, R@20: 95.8
2022-01-26 15:02:01   Not improved: 1 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-26 15:02:01   Start training epoch: 18
2022-01-26 15:02:01   Cache: 0 / 5
2022-01-26 15:06:35   Epoch[18](0/5): current batch triplet loss = 0.0028, average epoch triplet loss = 0.0018
2022-01-26 15:06:35   Cache: 1 / 5
2022-01-26 15:11:12   Epoch[18](1/5): current batch triplet loss = 0.0026, average epoch triplet loss = 0.0018
2022-01-26 15:11:12   Cache: 2 / 5
2022-01-26 15:15:48   Epoch[18](2/5): current batch triplet loss = 0.0008, average epoch triplet loss = 0.0018
2022-01-26 15:15:48   Cache: 3 / 5
2022-01-26 15:20:24   Epoch[18](3/5): current batch triplet loss = 0.0072, average epoch triplet loss = 0.0018
2022-01-26 15:20:24   Cache: 4 / 5
2022-01-26 15:25:00   Epoch[18](4/5): current batch triplet loss = 0.0047, average epoch triplet loss = 0.0018
2022-01-26 15:25:00   Finished epoch 18 in 0:22:59, average epoch triplet loss = 0.0018
2022-01-26 15:25:00   Extracting database features for evaluation/testing
2022-01-26 15:26:48   Extracting queries features for evaluation/testing
2022-01-26 15:28:11   Calculating recalls
2022-01-26 15:28:12   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 76.0, R@5: 89.7, R@10: 93.0, R@20: 96.0
2022-01-26 15:28:12   Not improved: 2 / 3: best R@5 = 89.9, current R@5 = 89.7
2022-01-26 15:28:12   Start training epoch: 19
2022-01-26 15:28:12   Cache: 0 / 5
2022-01-26 15:32:47   Epoch[19](0/5): current batch triplet loss = 0.0000, average epoch triplet loss = 0.0025
2022-01-26 15:32:47   Cache: 1 / 5
2022-01-26 15:37:23   Epoch[19](1/5): current batch triplet loss = 0.0051, average epoch triplet loss = 0.0026
2022-01-26 15:37:23   Cache: 2 / 5
2022-01-26 15:42:00   Epoch[19](2/5): current batch triplet loss = 0.0001, average epoch triplet loss = 0.0027
2022-01-26 15:42:00   Cache: 3 / 5
2022-01-26 15:46:38   Epoch[19](3/5): current batch triplet loss = 0.0045, average epoch triplet loss = 0.0027
2022-01-26 15:46:38   Cache: 4 / 5
2022-01-26 15:51:17   Epoch[19](4/5): current batch triplet loss = 0.0026, average epoch triplet loss = 0.0026
2022-01-26 15:51:17   Finished epoch 19 in 0:23:04, average epoch triplet loss = 0.0026
2022-01-26 15:51:17   Extracting database features for evaluation/testing
2022-01-26 15:53:03   Extracting queries features for evaluation/testing
2022-01-26 15:54:24   Calculating recalls
2022-01-26 15:54:25   Recalls on val set < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >: R@1: 75.8, R@5: 89.4, R@10: 93.2, R@20: 95.9
2022-01-26 15:54:25   Not improved: 3 / 3: best R@5 = 89.9, current R@5 = 89.4
2022-01-26 15:54:25   Performance did not improve for 3 epochs. Stop training.
2022-01-26 15:54:26   Best R@5: 89.9
2022-01-26 15:54:26   Trained for 20 epochs, in total in 1:18:28
2022-01-26 15:54:27   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-26 15:54:27   Extracting database features for evaluation/testing
2022-01-26 15:56:13   Extracting queries features for evaluation/testing
2022-01-26 15:57:27   Calculating recalls
2022-01-26 15:57:28   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 75.4, R@5: 89.1, R@10: 92.8, R@20: 95.3
2022-01-26 15:57:28   
Traceback (most recent call last):
  File "project_vg/train.py", line 222, in <module>
    test_ds = datasets_ws.BaseDataset(args, args.datasets_folder, test_dataset, "test")
  File "/content/project_vg/datasets_ws.py", line 60, in __init__
    if not os.path.exists(self.dataset_folder): raise FileNotFoundError(f"Folder {self.dataset_folder} does not exist")
FileNotFoundError: Folder /content/st_lucia/images/test does not exist

2022-01-28 21:11:00   Arguments: Namespace(aug_prob=0.5, cache_refresh_rate=1000, colab_folder='gem', data_aug=None, dataset_name='pitts30k', datasets_folder='/content/', device='cuda', epochs_num=50, exp_name='default', infer_batch_size=16, lr=1e-05, margin=0.1, neg_samples_num=1000, negs_num_per_query=10, num_clusters=64, num_workers=8, optimizer='adam', output_folder='drive/MyDrive/gem', patience=3, queries_per_epoch=5000, recall_values=[1, 5, 10, 20], seed=0, train_batch_size=4, train_positives_dist_threshold=10, type='GEM', val_positive_dist_threshold=25)
2022-01-28 21:11:00   The outputs are being saved in drive/MyDrive/gem
2022-01-28 21:11:00   Using 1 GPUs and 2 CPUs
2022-01-28 21:11:00   Loading dataset Pitts30k from folder /content/
2022-01-28 21:11:01   There are 96 queries without any positives within the training set. They won't be considered as they're useless for training.
2022-01-28 21:11:01   Train query set: < TripletsDataset, pitts30k - #database: 10000; #queries: 7320 >
2022-01-28 21:11:01   Val set: < BaseDataset, pitts30k - #database: 10000; #queries: 7608 >
2022-01-28 21:11:02   Train only conv4 of the ResNet-18 (remove conv5), freeze the previous ones
2022-01-28 21:11:02   Using GeM network
2022-01-28 21:11:05   using Adam optimizer
2022-01-28 21:11:05   Output dimension of the model is 256
2022-01-28 21:11:06   Patience: 3
2022-01-28 21:11:06   not improved num: 3
2022-01-28 21:11:06   Best R@5: 89.9
2022-01-28 21:11:06   Trained for 20 epochs, in total in 0:00:06
2022-01-28 21:11:08   Test set: < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >
2022-01-28 21:11:08   Extracting database features for evaluation/testing
2022-01-28 21:12:58   Extracting queries features for evaluation/testing
2022-01-28 21:14:13   Calculating recalls
2022-01-28 21:14:14   Recalls on < BaseDataset, pitts30k - #database: 10000; #queries: 6816 >: R@1: 75.4, R@5: 89.1, R@10: 92.8, R@20: 95.3
2022-01-28 21:14:14   Test set: < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >
2022-01-28 21:14:14   Extracting database features for evaluation/testing
2022-01-28 21:14:33   Extracting queries features for evaluation/testing
2022-01-28 21:14:50   Calculating recalls
2022-01-28 21:14:51   Recalls on < BaseDataset, st_lucia - #database: 1549; #queries: 1464 >: R@1: 48.9, R@5: 68.3, R@10: 75.1, R@20: 80.6
